# ğŸ§  Human Activity Recognition Model

This project uses a **Random Forest Classifier** to recognize human activities based on smartphone sensor data from the [UCI HAR Dataset](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones).

It classifies activities like walking, sitting, and lying down using accelerometer and gyroscope readings collected from smartphones.

---

## ğŸ“ Dataset

We use the **UCI HAR Dataset**, which includes:

- Measurements from 30 participants
- Sensor signals from a smartphone's accelerometer and gyroscope
- Pre-processed and normalized training and test data

ğŸ“‚ Folder structure:

---

## ğŸ§ª Activities Classified

The following 6 human activities are recognized:

1. ğŸš¶ WALKING  
2. ğŸ§—â€â™‚ï¸ WALKING_UPSTAIRS  
3. ğŸ§ WALKING_DOWNSTAIRS  
4. ğŸª‘ SITTING  
5. ğŸ§ STANDING  
6. ğŸ›Œ LAYING  

---

## âš™ï¸ Technology Stack

- **Language**: Python 3.10  
- **Libraries**:
  - `pandas`
  - `scikit-learn`
  - `matplotlib` (optional for plots)

- **Algorithm**: `RandomForestClassifier` from scikit-learn

---

## ğŸš€ How to Run the Project

1. ğŸ“¥ Clone the repository

```bash
git clone https://github.com/Manikanta-123456/Human-Activity-Recognization-Model.git
cd Human-Activity-Recognization-Model
Human-Activity-Recognization-Model/
â”œâ”€â”€ activity_recognition.py
â”œâ”€â”€ environment.yml
â””â”€â”€ UCI HAR Dataset/
python activity_recognition.py
Accuracy: 93.58%
Actual: WALKING, Predicted: WALKING
Actual: SITTING, Predicted: STANDING
Actual: STANDING, Predicted: STANDING
...
conda env create -f environment.yml
conda activate har-env
ğŸ‘¤ Author
Manikanta Pilli
ğŸ“§ Email: pillimanikanta44@gmail.com

---

